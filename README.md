# CIA 1: Cricket Player Selection - Bandit Algorithms

### Overview
Implemented and compared the performance of two different bandit algorithms:

- **Epsilon-Greedy**
- **Thompson Sampling**

These algorithms were applied to a simulated problem of cricket player selection, where the objective was to select players based on their performance under various match conditions.

### Key Features:
- Simulated cricket match conditions (e.g., Dry pitch, Wet pitch, Sunny, etc.)
- Player performance modeled dynamically based on match conditions
- Bandit algorithms used to select optimal players for matches

---

# CIA 2: MDP-based Reinforcement Learning (RL) Agent

### Overview
Implemented a **Markov Decision Process (MDP)**-based **Reinforcement Learning (RL)** agent to navigate a 100x100 grid with obstacles.

- **Algorithm**: Q-Learning
- The agent learns to navigate the grid by selecting actions that maximize the cumulative reward while avoiding obstacles.

### Key Features:
- 100x100 grid with obstacles
- Q-Learning algorithm for optimal decision-making
- Training agent to explore and optimize its path through the grid

---
